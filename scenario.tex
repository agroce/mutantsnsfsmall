\paragraph{Our Vision: A Day in the Life of a Systems Programmer}

\begin{framed} \emph{Our final research goal, to enable cooperation between mutation, developer intuition, and fuzzing and other automated testing systems, in a seamless fashion, is most easily expressed in a scenario, rather than as an explicit research program or set of questions.  It depends on the other proposed work, and on integration of the final products with automated testing systems.  Both PIs are expert in the use and enhancement of such tools.}
  \end{framed}

Laura is developing a data-management system for a NASA/JPL Mars rover.  She is responsible both for a catalog process that handles data products, including critical configuration files, for other modules and the implementation of the low-level interface to custom, radiation-hardened, flash software.  Hardware changes have made certain design alterations to existing NASA-developed file systems essential, and Laura's expertise in the file systemhas resulted in her also being assigned the task of constructing the higher-level module that manages access to persistent storage.
Laura has, in the process of developing the code, also developed a set of manually constructed unit tests and harnesses supporting automated test generation for the system, using IDE-supported MDD.  She employs static analysis tools, with additional custom rules developed by the rover software team and the NASA facility's software tooling experts.  Laura has also added a few custom rules of her own that capture patterns she wants to enforce on herself with respect to the use of the low-level file system API.

Today, Laura is continuing an ongoing effort at changing functionality to the catalog and the file system, rewriting the ``rename'' call to provide a more restrictive set of allowed renames than the POSIX standard.  After reviewing the risks of arbitrary rename, the software team has agreed this is a restriction that protects the integrity of data better, while retaining all functionality ground operators might need to fix problems in the file system structure.  As part of this revision, Laura realized that without certain renames being allowed, a simpler scheme for enforcing atomicity of renames would work that could make mounting and checking the file system both faster and less complex (thus likely less buggy).

Laura reaches a point where she believes her change is fully implemented and the tests have been revised to check the changed behavior.  She looks at a panel in her IDE showing Test Effectiveness, and notices that there are four Missed Bugs for her to examine.  She clicks on the top one, and the IDE focuses on a line of code in the rename function.  The display shows a change to that line, and says that altering the line in the way shown changes the file system binary but is not detected by any existing manual test or static analysis rule, and has not been detected in two minutes of fuzzing, across multiple cores, or by any stored fuzzing-generated test.

Laura thinks for a while about the change made, which involves passing a flag to the call that disables an expensive ``sanity check'' on header values for a file, to be used in contexts where the header has just been written and checked.  She thinks the current context is unsafe, and the check is required.  She knows that the danger is when there is a hardware failure of a certain kind, so she goes to the hardware emulator code that she uses to run tests without access to the rover testbeds, and requests the system to generate tests that target not just the mutated line of code (the system has already generated a number of these for her to examine), but the additional line with the relevant simulated hardware failure injection.  The fuzzers run in a targeted mode for a few minutes, and show Laura traces.  She runs some of these through a debugger, goes to the blackboard and calls in a colleague to discuss her reasoning.  They agree the check is indeed not needed, which will result in a small optimization in the file system.  Given the process she uses for developing her code, and the high quality of automated tests associated, Laura feels confident, given the argument, in optimizing the code.  The system now informs her that a very different mutant has the highest priority among uncaught bugs.  Of course, the system couldn't detect the mutant to the new version of the code, the one enabling the check, but Laura long ago informed the system that adding the check was never going to break any tests (the test is too cheap to produce interesting performance test violations, in any one location).  It therefore won't trouble her with this problem, now.  A small symbol attached to the parameter on the line of code does allow Laura to see that this line has an ignored unkilled mutant, which she can inspect if she is worried about the code.

Because Laura has been using the ``MDD'' process all along, her additional confidence tests will detect any problems with the optimization is not just based on mutation analysis of her current code.  Instead, it is based on mutants of \emph{all the versions of the design and functionaity she has implemented}; if a problem is representable by a mutant of code no longer present (the older rename behavior, for example), then while not forming a basis for mutant alerts now, that behavior, in terms of API calls and hardware simulation choices, will be permanently in place in the stored corpus of fuzzing tests or manually constructed tests to address mutants.  So long as Laura allows the tool to guide her to always keep a high mutation score, she will keep these ``mutant-regression'' tests in place as an abstract form of the varying possibilities of her design, and the assurance tasks associated with that design perimeter.