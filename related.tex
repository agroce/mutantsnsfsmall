\section{Related Work}

\subsection{Bug Triage and Distance Metrics in Software Engineering}

A fundamental insight of this proposal is that the problem of
presenting mutants to a user is conceptually similar to the ``fuzzer
taming''/crash bucketing/bug triage problem studied in automated
testing research~\cite{PLDI13,SemCrash}.  This proposal's approach is centered on
the idea of computing distances between mutants.  The use of distance metrics in software engineering for a variety of
purposes is long-standing.  Almost all such uses are
essentially spectrum-based \cite{RepsSpectra} (that is, using counts
of coverage of code entities), except for some work in model-checking
\cite{GroceDist,ChakiLev} and some of the metrics in PI Groce's recent fuzzer
taming work \cite{PLDI13}.  Reneiris and Reiss initially proposed
using distance between executions to localize faults
\cite{NearNeighbor}, and Liu and Han \cite{Liu06}, Vangala \cite{VangalaDist}, and others have
followed this line with various metrics. %(in their case, using the
%localization of a spectrum-based method to determine distance).
%Vangala et al. proposed using distance to cluster test cases to
%improve diversity and eliminate duplicates \cite{VangalaDist}.
Methods for clustering to identify bugs all rely on a distance \cite{Podgurski04}.  PI Groce's previous work
has used distance metrics for a variety of purposes
\cite{PLDI13,icst2014,issta14}.  Recently, PI Groce proposed a novel,
causal metric for fuzzer taming and fault localization, itself based on
mutation testing results \cite{distMut}.  Work on
presenting a few well-chosen mutants
is also related to PI Groce's own work on end-user testing of machine learning
systems \cite{EndUserMistake,OnlyOracle}, where the limits of human
patience are a key factor.


\subsection{Mutation Testing}

There is a vast body of work on mutation testing or analysis.  Mathur attributes~\cite{mathur2012foundations} the original idea for mutation analysis
to Lipton. Foundational assumptions and
theory were first proposed by DeMillo et al.~\cite{demillo1978hints},
and the approach was first implemented by Budd et al.~\cite{budd1980theoretical}.
%Mutation analysis as a theory relies on two fundamental
%assumptions --- \emph{the competent programmer hypothesis},
%and \emph{the coupling effect}, both of which have been widely
%studied~\cite{wah2000atheoretical,wah2003ananalysis,gopinath2017the,offutt1989thecoupling,offutt1992investigations,langdon2010efficient,gopinath2017the,gopinath2014mutations}. This
%proposal is more focused on the practical effectiveness of
%mutation testing than on theoretical justifications.

It has long been argued~\cite{budd1980mutation} that mutation analysis is \emph{stronger}
than other coverage measures. The subsumption of multiple coverage
measures by mutation analysis, including all the basic coverage measures~\cite{myer1979art}
was shown by Offutt~\cite{offutt1996subsumption}, and data flow
subsumption was demonstrated by Mathur~\cite{mathur1994empirical}.
Daran et al.~\cite{daran1996software} found that mutation analysis produces
faults that are similar to actual faults in terms of the error traces produced. Andrews et
al.~\cite{andrews2005mutation,andrews2006using} found that ease of detection
of mutants was similar to that of real faults when compared to manually
generated faults (in that manually generated faults were harder to find).
Recent research by Just et al.~\cite{just2014mutants} using 357 real faults
showed that in 75\% of cases, mutation score and test case
effectiveness improved together, which is a strong relationship
compared to the same coupling for coverage (46\%).  More recently,
Papadakis et. al~\cite{papadakis2018mutation} showed in a large scale study that the relation is also in some sense weak; indeed
they summarize their work by stating that ``mutants provide good guidance for improving the
fault detection of test suites, but their correlation with fault
detection [is] weak,'' which is a foundational assumption of this
proposal.  Ahmed et al., using a very different approach, reached a similar
conclusion about the potentially high value for suite improvement, but weak correlation of mutation
analysis results~\cite{ahmed_testedness}.

Cost of execution is often~\cite{jia2011analysis} considered 
to be the most problematic aspect of practical mutation testing.
Numerous approaches exist, that seek to reduce the cost of mutation
analysis. Offutt and Untch~\cite{offutt2001mutation} categorize these,
as: do \textit{fewer}, do \textit{smarter}, and do \textit{faster} approaches.
Operator selection, mutant sampling, and mutant clustering fall under
\textit{do fewer} --- approaches that seek to reduce the number of mutants
evaluated.  The \emph{do smarter} approaches seek to reduce the time taken
for the entire mutation analysis by intelligently managing the various phases.
Similarly, \textit{do faster} approaches seek to
reduce the time taken for evaluation of a single mutant, and include
mutant schema generation, code patching, and other methods.

%The \emph{do fewer} approaches, especially simple random sampling,
%debuted with the initial research in mutation
%analysis~\cite{budd1980mutation,acree1980mutation}, where it was noticed that
%even a 10\% random sample of mutants can on average be almost as effective (99\%)
%as the complete set of mutants..
%Sampling was further investigated by Mathur~\cite{mathur1991performance}, Wong et
%al.~\cite{wong1993mutation,wong1995reducing}, and Offutt et al.~\cite{offutt1993experimental}.

Determining relative merits of selective mutation strategies such as operator
selection and random sampling has long been an active field of research~\cite{wong1995reducing,mresa1999efficiency,zhang2010isoperator} 
%Skew in fault representativeness among mutants was initially noticed by Budd et
%al.~\cite{budd1980mutation} who found that particular types of mutants are
%representative for particular kinds of faults. Constrained mutation was
%pioneered by Mathur~\cite{mathur1991performance,mathur1993evaluation}
%and was further investigated by Wong et al.~\cite{wong1994constrained}.
%An extension of this approach called $n$-selection was suggested by
%Offutt et al.~\cite{offutt1993experimental} where the most numerous
%mutation operators were removed one at a time. A set of guidelines for operator selection
%was identified and evaluated by Barbosa et al.\cite{barbosa2001toward}.
Namin et al.~\cite{namin2006finding,namin2008sufficient} formulated the
concept of \emph{sufficient mutation operators}, and
Untch~\cite{untch2009onreduced} even proposed simply using statement
deletion as ``the'' mutation operator.  Deng et al.~\cite{deng2013empirical} extended the deletion operator for diverse
language elements, and obtained an effectiveness of 92\% while reducing the
number of mutants by 80\%.
The subsumption of individual mutants and mutation operators is also an active
area of research~\cite{gopinath2016measuring,shin2016theoretical,lindstrom2015redundant}.
%Higher order mutants (HOM) aim to improve the quality of
%mutants by combining simpler mutants into more complex mutants. Jia et
%al.~\cite{jia2009higher,jia2008constructing}, found that the number of mutants
%can be reduced by 50\% by making use of subsumption of simpler mutants
%by higher order mutants.
Mutation clustering\cite{derezinska2015toward,strug2012machine,hussain2008mutation} is another \emph{do-fewer}
approach where similar mutants are identified based on various
properties.

There has been extensive work on comparison of mutation
reduction strategies~\cite{zhang2010isoperator,zhang2013operator}.
Zhang et al.~\cite{zhang2014an} investigated the scalability of
selective mutation by considering how well a randomly sampled set of mutants
represent the original population. 
In previous work~\cite{gopinath2016on} PI Groce showed that there is
an upper bound on the improvement
in \emph{mean effectiveness} that is possible using even
an ideal mutation reduction strategy using post-hoc oracular knowledge of mutant
kills. We later extended that result by evaluating the actual improvement
achieved by extant mutation reduction strategies, when they do not
unrealistically have access to the
mutant kills achieved~\cite{gopinath2017mutation}.  Recent work on Predictive 
Mutation Testing (PMT)~\cite{zhang2016predictive} applies machine 
learning to build a model that can predict mutation results without 
actually running mutation testing, a novel and promising
\emph{do-smarter} approach.



\subsubsection{Practical Mutation Analysis}

The above work largely focuses on computing or at least estimating the
total mutation score of a
test suite, efficiently.  The assumption is that mutation testing is
meant to be, like a coverage metric, a kind of ``evaluation'' of a
test suite, a number used to say ``this is a good test suite'' or at
least ``this is a better test suite than that test suite.''  In contrast,
%important for some real-world purposes (evaluating QA efforts) and
%certainly for software testing research, that is not the focus of 
this proposal considers the problem of presenting unkilled mutations to
a developer or test engineer in a way that facilitates the improvement
of a test suite and the detection of faults.  This is inspired by PI Groce's
previous work on using mutation to find defects in formal verification
and automated test generation
efforts~\cite{groce2015verified,groce2018verified,mutKernel}.

Very recent work by Papadakis et al. (some unpublished in a conference
of journal at the time this proposal was written) has 
aimed, unusually, at predicting the ``quality'' of~\cite{MutQuality}
or even prioritizing~\cite{FaRM} mutants, to rank fault-revealing
mutants highly so that users can produce tests to find faults.  This
work is highly relevant to this proposal's aims, but focuses on a single static
pass to rank mutants by their fault-revealing potential, informed by
(possibly cross-project)
data on fault-revealing tests.  There is no feedback loop, or ability
to indicate the importance of various faults in the program under
test, and the language support issue is dodged by targeting LLVM
bitcode.  Nonetheless, the goals, methods, and results of this work
will inform this proposal's approach, in particular in the utility estimation
aspect that balances FPF-determined novelty.

The single most relevant work by others is to be found in a
report on actual techniques in use at Google for applying mutation
testing to real-world projects~\cite{MutGoogle}.  Their approach also
uses a notion of feedback, but this is manually handled and based on
using a classification scheme to heuristically throw out ``arid''
(likely not to be actionable)
mutants; due to the size of Google's code base and the integration of
their approach in Google's code review process, there is also a
decision to only allow one mutation (initially randomly decided) per
line of code.  While the underlying motivation, of giving developers
actionable information rather than computing a mutation score, is
similar, and the idea of using some form of ``feedback'' is common,
this approach considered in this proposal targets the individual developing, testing, or verifying a particular software
element (either a small project, or a component of a project), and
assumes an iterative process, where developers consider one unkilled
mutant at a time.  The Google approach does not attempt to prioritize
the unkilled mutants it surfaces, or support custom mutation
operators, or learn an individual testing effort's characteristics.
It is an attempt to select mutants
in an industrial scale code review setting, not an effort to propose a
new way to construct or enhance test suites; e.g., it only even
proposes mutants of code in a diff with a previous version of the
code, which makes it completely unusable in after-the-fact testing and
verification efforts.  Further, it uses
Google-wide coding conventions and developer suggestions to fix
heuristics such as ``avoid mutation of logging statements'' rather
than trying to learn (with human assistance) such heuristics for
projects that may vary widely in language and coding style.  
The techniques used in this proposal may be useful in generalizing or enhancing an
effort such as Google's, however, and share the focus on mutants as
tools for focusing developer/tester attention and producing action on the
part of humans, not computing a mutation score.  Indeed, the report
itself allows that the current approach does not scale, since it
requires extensive manual support for each heuristic and language, a
problem this proposal aims to directly address.

More broadly, a paper by the
authors of the Google report and a group of academic mutation testing
researchers~\cite{ivankovic2018industrial}, uses the Google effort to
propose a notion of productive and unproductive mutants.  Their
concepts are highly related to this proposal's goals, but again centered on a
diff-focused, large-scale industrial setting, rather than an approach
that, like TDD, may also be applied to smaller coding efforts in a more
isolated setting, such as development of embedded software, where
crowdsourcing is impractical.  Another key difference is that, while their
work used EvoSuite to enhance a test suite to kill additional mutants,
the assumption was that most suite enhancement would be due to
developers adding manual tests.  Furthermore, we argue mutants
are neither ``productive'' or ``unproductive'' in an absolute sense, but
rather the value of a mutant also depends on previous mutants a
developer has manually examined, and the results of that examination;
this project embodies this concept in the FPF-centric workflow.

A second thrust of the efforts in this proposal is to simplify the
development, maintenance, and (especially) extension of mutation
testing tools by using an extension of regular expressions to define
mutation operators, and separating the generation of mutants from
language or build-environment specific techniques for pruning invalid
mutants.  This aspect of the proposal primarily builds on PI Groce's initial work on the topic of
regular-expression-based mutant generation~\cite{regexpMut} and
{\bf DISCUSS COMBY}.  %Trivial compiler equivalence~\cite{TCE} is a key
%technology for supporting effective any-language mutation; especially
%in the context of this proposal, where executing all mutants is not
%the goal, simply letting the compiler handle many validity and
%equivalence questions is a simple and effective approach.