\section{Closely-Related Work}

\noindent\textbf{Mutation Testing.}
%
There is a vast body of work on mutation testing or analysis, an area whose foundations date
to the late 70's~\cite{demillo1978hints,budd1980theoretical}.  
%Mathur
%attributes~\cite{mathur2012foundations} the original idea for mutation analysis 
%to Lipton. 
%
%It has long been argued~\cite{budd1980mutation} that mutation analysis is \emph{stronger}
%than other coverage measures. 
Mutation analysis has been shown to subsume multiple coverage measures,
including all the basic coverage
measures~\cite{myer1979art,offutt1996subsumption} and data flow
subsumption measures~\cite{mathur1994empirical}.  
Andrews et al.~\cite{andrews2005mutation,andrews2006using} found that ease of detection
of mutants was similar to that of real faults.
The relationship between
mutation score and test case effectiveness is sometimes empirically stronger
than 
coverage~\cite{just2014mutants}. However, Papadakis et
al.~\cite{papadakis2018mutation} recently 
showed in a large scale study that this relationship is sometimes weak: ``mutants provide good guidance for improving the
fault detection of test suites, but their correlation with fault
detection [is] weak.''  Ahmed et al. reached similar
conclusions~\cite{ahmed_testedness}.  This is a foundational assumption of this proposal.  
%Daran et al.~\cite{daran1996software} found that mutation analysis produces
%faults that are similar to actual faults in terms of the error traces
%produced.

%Cost of execution is often~\cite{jia2011analysis} considered
%to be the most problematic aspect of practical mutation testing.
Numerous approaches seek to reduce the cost~\cite{jia2011analysis} of mutation
analysis. Offutt and Untch~\cite{offutt2001mutation} categorize these,
as: do \textit{fewer} (e.g., operator selection, mutant sampling or clustering),
do \textit{smarter} (i.e., intelligent organization to reduce time taken for the
entire analysis), and do \textit{faster} (i.e., in terms of single mutant
evaluation time) approaches. 
%Operator selection, mutant sampling, and mutant clustering fall under
%\textit{do fewer} --- approaches that seek to reduce the number of mutants
%evaluated.  
%\emph{Do smarter} approaches seek to reduce the time taken
%for the entire mutation analysis by intelligent organization.
%\textit{Do faster} approaches seek to
%reduce the time taken for evaluation of a single mutant.%, and include
%mutant schema generation, code patching, and other methods.
%The \emph{do fewer} approaches, especially simple random sampling,
%debuted with the initial research in mutation
%analysis~\cite{budd1980mutation,acree1980mutation}, where it was noticed that
%even a 10\% random sample of mutants can on average be almost as effective (99\%)
%as the complete set of mutants..
%Sampling was further investigated by Mathur~\cite{mathur1991performance}, Wong et
%al.~\cite{wong1993mutation,wong1995reducing}, and Offutt et al.~\cite{offutt1993experimental}.
Determining relative merits of selective mutation strategies such as operator
selection and random sampling has long been an active field of
research~\cite{wong1995reducing,mresa1999efficiency,zhang2010isoperator} 
%Skew in fault representativeness among mutants was initially noticed by Budd et
%al.~\cite{budd1980mutation} who found that particular types of mutants are
%representative for particular kinds of faults. Constrained mutation was
%pioneered by Mathur~\cite{mathur1991performance,mathur1993evaluation}
%and was further investigated by Wong et al.~\cite{wong1994constrained}.
%An extension of this approach called $n$-selection was suggested by
%Offutt et al.~\cite{offutt1993experimental} where the most numerous
%mutation operators were removed one at a time. A set of guidelines for operator selection
%was identified and evaluated by Barbosa et al.\cite{barbosa2001toward}.
Namin et al.~\cite{namin2006finding,namin2008sufficient} formulated the
concept of \emph{sufficient mutation operators}, and
others~\cite{untch2009onreduced, deng2013empirical} even proposed simply using statement
deletion as ``the'' mutation operator.  
%Deng et al.~\cite{deng2013empirical} extended the deletion operator for diverse
%language elements, and obtained an effectiveness of 92\% while reducing the
%number of mutants by 80\%.
The subsumption of individual mutants and mutation operators is also an active
area of research~\cite{gopinath2016measuring,shin2016theoretical,lindstrom2015redundant}.
%Higher order mutants (HOM) aim to improve the quality of
%mutants by combining simpler mutants into more complex mutants. Jia et
%al.~\cite{jia2009higher,jia2008constructing}, found that the number of mutants
%can be reduced by 50\% by making use of subsumption of simpler mutants
%by higher order mutants.
Mutation
clustering\cite{derezinska2015toward,strug2012machine,hussain2008mutation} is
another \emph{do-fewer} approach where similar mutants are identified based on
various properties.  One aspect of our proposal is a fundamentally
different \emph{do-fewer} method that combines FPF-novelty, utility
prediction, and user interaction for a more radical reduction in
mutants run.

%\textbf{FIXME: maybe 1-2 sentences on how we're different,
%  given that we have a totally different focus in this proposal, in lieu of the
%  paragraph that I cut (still in comments).}

% CLG: I propose we cut this, since we're not doing this. But I will not die on
% this hill. 
%
% There has been extensive work on comparison of mutation
% reduction strategies~\cite{zhang2010isoperator,zhang2013operator}.
% Zhang et al.~\cite{zhang2014an} investigated the scalability of
% selective mutation.
% In previous work~\cite{gopinath2016on} PI Groce showed that there is
% an upper bound on the improvement
% in \emph{mean effectiveness} that is possible using even
% an ideal mutation reduction strategy using post-hoc oracular knowledge of mutant
% kills, and later evaluated the actual improvement
% achieved by extant mutation reduction strategies, when they do not
% unrealistically have access to
% mutant kills~\cite{gopinath2017mutation}.  Recent work on Predictive
% Mutation Testing (PMT)~\cite{zhang2016predictive} applies machine
% learning to build a model that can predict mutation results without
% actually running mutation testing.

\paragraph{Practical Mutation Analysis}
%
The above work largely focuses on computing or at least estimating the
total mutation score of a
test suite.  The assumption is that mutation testing is
meant to be, like a coverage metric, a kind of ``evaluation'' of a
test suite, a number used to say ``this is a good test suite'' or at
least ``this is a better test suite than that test suite.''  In contrast,
%important for some real-world purposes (evaluating QA efforts) and
%certainly for software testing research, that is not the focus of
this proposal considers the problem of presenting unkilled mutations to
a developer or test engineer in a way that facilitates the improvement
of a test suite and the detection of faults.  This is inspired by PI Groce's
previous work on using mutation to find defects in formal verification
and automated test generation
efforts~\cite{groce2015verified,groce2018verified,mutKernel}.

Very recent work by Papadakis et al. (some unpublished in a conference
of journal at the time this proposal was written) has
aimed, unusually, at predicting the ``quality'' of~\cite{MutQuality}
or even prioritizing~\cite{FaRM} mutants, to rank fault-revealing
mutants highly so that users can produce tests to find faults.  This
work is highly relevant to this proposal's aims, but focuses on a single static
pass to rank mutants by their fault-revealing potential, informed by
(possibly cross-project)
data on fault-revealing tests.  There is no feedback loop, or ability
to indicate the importance of various faults in the program under
test, and the language support issue is dodged by targeting LLVM
bitcode.  Nonetheless, the goals, methods, and results of this work
will inform this proposal's approach, in particular in the utility estimation
aspect that balances FPF-determined novelty.

The single most relevant work by others is to be found in a
report on actual techniques in use at Google for applying mutation
testing to real-world projects~\cite{MutGoogle}.  Their approach also
uses a notion of feedback, but this is manually handled and based on
using a classification scheme to heuristically throw out ``arid''
(likely not to be actionable)
mutants; due to the size of Google's code base and the integration of
their approach in Google's code review process, there is also a
decision to only allow one mutation (initially randomly decided) per
line of code.  While the underlying motivation, of giving developers
actionable information rather than computing a mutation score, is
similar, and the idea of using some form of ``feedback'' is common,
this approach considered in this proposal targets the individual developing, testing, or verifying a particular software
element (either a small project, or a component of a project), and
assumes an iterative process, where developers consider one unkilled
mutant at a time.  The Google approach does not attempt to prioritize
the unkilled mutants it surfaces, or support custom mutation
operators, or learn an individual testing effort's characteristics.
It is an attempt to select mutants
in an industrial scale code review setting, not an effort to propose a
new way to construct or enhance test suites; e.g., it only even
proposes mutants of code in a diff with a previous version of the
code, which makes it completely unusable in after-the-fact testing and
verification efforts.  Further, it uses
Google-wide coding conventions and developer suggestions to fix
heuristics such as ``avoid mutation of logging statements'' rather
than trying to learn (with human assistance) such heuristics for
projects that may vary widely in language and coding style.
The techniques used in this proposal may be useful in generalizing or enhancing an
effort such as Google's, however, and share the focus on mutants as
tools for focusing developer/tester attention and producing action on the
part of humans, not computing a mutation score.  Indeed, the report
itself allows that the current approach does not scale, since it
requires extensive manual support for each heuristic and language, a
problem this proposal aims to directly address.

More broadly, a paper by the
authors of the Google report and a group of academic mutation testing
researchers~\cite{ivankovic2018industrial}, uses the Google effort to
propose a notion of productive and unproductive mutants.  Their
concepts are highly related to this proposal's goals, but again centered on a
diff-focused, large-scale industrial setting, rather than an approach
that, like TDD, may also be applied to smaller coding efforts in a more
isolated setting, such as development of embedded software, where
crowdsourcing is impractical.  Another key difference is that, while their
work used EvoSuite to enhance a test suite to kill additional mutants,
the assumption was that most suite enhancement would be due to
developers adding manual tests.  Furthermore, we argue mutants
are neither ``productive'' or ``unproductive'' in an absolute sense, but
rather the value of a mutant also depends on previous mutants a
developer has manually examined, and the results of that examination;
this project embodies this concept in the FPF-centric workflow.

A second thrust of the efforts in this proposal is to simplify the
development, maintenance, and (especially) extension of mutation
testing tools by
expanding the expressive power for
% using an extension of regular expressions to define
mutation operators through domain-specific templates, and separating the generation of mutants from
language or build-environment specific techniques for pruning invalid
mutants.  This aspect of the proposal primarily builds on PI Groce's initial work on the topic of
regular-expression-based mutant generation~\cite{regexpMut} and
PI Le Goues's work on declarative transformation for multiple languages~\cite{rvt-ppc}.
% {\bf CLG: DISCUSS COMBY}.  %Trivial compiler equivalence~\cite{TCE} is a key
%technology for supporting effective any-language mutation; especially
%in the context of this proposal, where executing all mutants is not
%the goal, simply letting the compiler handle many validity and
%equivalence questions is a simple and effective approach.

\paragraph{Bug Triage and Distance Metrics in Software Engineering}
%
%A fundamental insight of this proposal is that the problem of
%presenting mutants to a user is conceptually similar to the ``fuzzer
%taming''/crash bucketing/bug triage problem studied in automated
%testing research~\cite{PLDI13,SemCrash}.  
This proposal's approach is centered on
the idea of computing distances between mutants.  The use of distance metrics in
software engineering for a variety of  
purposes is long-standing.  Almost all such uses are
essentially spectrum-based \cite{RepsSpectra} (that is, using counts
of coverage of code entities), except for some work in model-checking
\cite{GroceDist,ChakiLev} and some of the metrics in PI Groce's recent fuzzer
taming work \cite{PLDI13}.  Reneiris and Reiss initially proposed
using distance between executions to localize faults
\cite{NearNeighbor}, and Liu and Han \cite{Liu06}, Vangala \cite{VangalaDist}, and others have
followed this line with various metrics.
Methods for clustering to identify bugs all rely on a distance \cite{Podgurski04}.  PI Groce's previous work
has used distance metrics for a variety of purposes 
\cite{PLDI13,icst2014,issta14}.  Recently, PI Groce proposed a novel,
causal metric for fuzzer taming and fault localization, itself based on
mutation testing results \cite{distMut}.  Work on
presenting a few well-chosen mutants
is also related to PI Groce's own work on end-user testing of machine learning
systems \cite{EndUserMistake,OnlyOracle}, where the limits of human
patience are a key factor.  
