%\section{Background and Preliminary Research}

\section{Falsification-Driven Verification and Testing}

\textbf{FIXME: this used to be background, but I integrated the prior work on
  universalmutator and FPF for fuzzer taming into the proposed work.  I think
  this content can probably be divided up into the intro, the overview of the
  proposed work, and possibly related work?  Thus eliminating the need for a
  background section altogether.  I just haven't had a chance to try it, yet.}
PI Groce and colleagues recently proposed a novel approach to
formal verification and automated testing 
combining Karl Popper's falsification-based notion of
scientific discovery~\cite{Popper,popperconjectures} with mutation
testing~\cite{groce2015verified,groce2018verified,mutKernel}.
The heart of the idea is (1) a surviving non-equivalent mutant 
\emph{falsifies} the claim that a given
formal verification or test effort captures a full notion of
correctness and (2) refining a
verification or testing effort by repeated efforts at falsification is an
effective method for ensuring the quality of verification and testing
efforts.  This
work resulted in the identification of multiple previously unknown faults in
the Linux kernel's
RCU~\cite{MathieuDesnoyers2012URCU,DinakarGuniguntala2008IBMSysJ,McKenney:2013:SDS:2483852.2483867}
module and the {\tt pyfakefs} Python mock file
system~\cite{pyfakefs}, despite the existence of very-high-quality
automated test generation efforts for these
systems~\cite{rcutorture,TSTL}.  Out preliminary work on
falsification-driven methods proposed a number of algorithms and
methods for finding bugs in testing and verification
harnesses, rather than the code under test.  At a high level, however,
the core concept was simple:  users should examine all unkilled
mutants of a program, and for each mutant either understand why it is
equivalent or uninteresting, or actually construct a way to kill it.  In a sense, this actually harkens back to the
earliest ideas about mutation testing, but with 
much more automated support. 

Unfortunately, the
methods proposed were, while useful, limited in applicability.  They simply assumed that the number of unkilled mutants was
small, and focused on solving the problem of helping a developer or
test engineer move from an unkilled mutant to killing it.
In practice, however, human
attention does not scale to analyzing large numbers of 
unkilled mutants without further assistance in ``triaging'' the mutants.  The process of manually examining mutants bears a
resemblance to the problem of manual confirmation of results from a
machine-learning classifier~\cite{OnlyOracle,EndUserMistake}, where even highly-motivated scientific
users are typically unwilling to examine more than a few tens of
potentially problematic results~\cite{Segal}.
The manual mutant-examination process was simply not feasible unless the number of
unkilled mutants was relatively small, because the testing was already
very high quality.  For sufficiently large software systems, even a
very high quality testing effort may fail to kill a
large absolute number of mutants.  The original approach simply provided no way to
scale human efforts to such a needle-in-a-haystack setting. 

This project aims to make the falsification-driven approach to verification and testing feasible for larger
projects, and those with lower mutation scores.
Because this proposal's feedback-driven approach no longer requires small absolute numbers of
unkilled mutants, it extends the applicability of the approach
to using manual tests to kill mutants, which was not in
scope when extremely high kill-rates were required.






