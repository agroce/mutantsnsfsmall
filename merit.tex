This project addresses core problems not limited to practical application of mutation testing, but generalizable to fundamental issues in software engineering and program semantics, e.g., how to represent source changes and (mostly statically) predict the similarity of their impact on semantics, and predict which tests are likely to detect these changes.  How can novelty of information presented to a user be effectively balanced with a-priori predictions of the utility of that information, where likely-high-utility data points may also be similar to each other?  How can user feedback best be incorporated into such efforts?  This project also considers connections raised by preliminary work, concerning new methodologies for testing/verification effort development.  Can theoretical ideas about the nature of scientific discovery~\cite{Popper,popperconjectures,lakatos} be applied to such efforts?  Is falsification by alternative hypotheses about the power of a testing/verification effort translatable to an actionable, effective approach for building systems~\cite{groce2015verified,groce2018verified}? 
The work on any-language mutation testing looks at syntactic patterns common to almost all programming languages, and relies on categorizing languages into families based on similarity, including of syntactic to semantic mappings.
%and how they share common meaningful syntactic changes that translate to interesting semantic changes.  