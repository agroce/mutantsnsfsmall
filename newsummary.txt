Overview: The core problem this project aims to address is making the use of program mutants practical in nonresearch settings, in a way that meets developers' or test engineers' needs; that is, making it possible for someone creating or enhancing a test suite, or developing code and test suite in tandem, to (1) use "just enough" mutation testing for their needs, maximizing benefit gained in exchange for work performed, and (2) to work in any programming language without worrying about the quality of tool support provided for mutation testing, and without sacrificing the ease of understanding of source-based mutants, while easily adding custom mutation operators that target their specific software development task. This project aims to adapt the Furthest-Point-First metric previously used in fuzzer bug triaging to the problem of maximizing the novelty of mutants examined by a user, in order to make it possible to quickly discover unkilled mutants that expose serious defects in a testing or verification effort. However, novelty alone is not sufficient: feedback-driven mutation testing must also help users avoid (uninteresting) equivalent mutants, kill mutants high in the dominance hierarchy, and (most importantly) incorporate user feedback.  If a user marks a mutant as uninteresting, or equivalent, or (especially) high impact, then that information must be used to inform the ranking of future mutants as well. In order to make such an approach maximally valuable, this project also proposes to improve the state-of-the-art in source level multilingual mutant generation, allowing users to easily generate mutants for new programming languages, or even for custom DSLs that are part of a specific project.

Intellectual Merit:

This project addresses core problems not limited to practical application of mutation testing to improve test efforts in a user-centered way, but generalizable to fundamental issues in software engineering and program semantics. E.g., how can we represent program changes and (mostly statically) predict the similarity of their impact on program semantics, and which tests are likely to detect these changes. How can novelty of information presented to a user be effectively balanced with a-priori predictions of the utility of that information, where likely-high-utility data points may also be unfortunately similar to each other? How can user feedback be incorporated into such efforts without over-burdening human users?  This project also considers connections raised by preliminary work, concerning effective methodologies for program and testing/verification effort development. Can theoretical ideas about the nature of scientific discovery be applied to such efforts? Is falsification by alternative hypotheses about the correctness of a system or power of a testing/verification effort translatable to an actionable, effective approach for building systems? The work on any-language mutation testing looks at syntactic patterns common to almost all programming languages, and relies on categorizing languages into families based on similarity and how they share common meaningful syntactic changes that translate to interesting semantic changes. Additionally, we will perform the first rigorous human experiments to determine the effectiveness of mutants in improving test suites and oracles.

Broader Impacts:

A key element of broader outreach will be to report bugs discovered during testing experiments, and contribute improved test suites to critical open source projects. To that end, this proposal will primarily target real world systems in experiments, in hopes of improving their quality, and the quality of their testing. Current targets include automated testing for the Linux kernel RCU module, Google and Mozilla JavaScript engines, a variety of C compilers (including GCC and LLVM), YAFFS2 and other file systems, Google's Go compiler, a large set of Unix utilities, NASA's F Prime architecture, and a large number of Python libraries (including some of the most widely used libraries, and key scientific and numeric analysis packages). In previous work, discussions with working test engineers at Mozilla, Google, and NASA have significantly informed the PIs' research efforts, and this is certain to continue. In the long term, a mutation-driven development paradigm might result in easier development of critical software components in tandem with an extremely high-quality, specification-defining, automated test suite or full formal verification harness.

Keywords: mutation testing, automated test generation, validation of verification and testing efforts, oracle improvement
